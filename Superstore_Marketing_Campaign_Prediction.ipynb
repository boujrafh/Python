{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boujrafh/Python/blob/main/Superstore_Marketing_Campaign_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "GHsVO0XG3wX9"
      },
      "id": "GHsVO0XG3wX9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "00a179f1",
      "metadata": {
        "id": "00a179f1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "sns.set_theme(color_codes=True)\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "da0ac5ad",
      "metadata": {
        "id": "da0ac5ad",
        "outputId": "cf370fdd-ea3a-4653-a57c-77de66e87a26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-a7430aa8307c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'superstore_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'superstore_data.csv'"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('superstore_data.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "899757ca",
      "metadata": {
        "id": "899757ca"
      },
      "source": [
        "# Data Preprocessing Part 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f8f1aa6",
      "metadata": {
        "id": "5f8f1aa6"
      },
      "outputs": [],
      "source": [
        "df.drop(columns='Id', inplace=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bed7004",
      "metadata": {
        "id": "2bed7004"
      },
      "outputs": [],
      "source": [
        "#Check the number of unique value from all of the object datatype\n",
        "df.select_dtypes(include='object').nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8480355c",
      "metadata": {
        "id": "8480355c"
      },
      "outputs": [],
      "source": [
        "# Extract the last four digits from the 'Dt_Customer' column\n",
        "df['Dt_Customer'] = df['Dt_Customer'].str[-4:]\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d0d9074",
      "metadata": {
        "id": "2d0d9074"
      },
      "outputs": [],
      "source": [
        "#Check the number of unique value from all of the object datatype\n",
        "df.select_dtypes(include='object').nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2863a428",
      "metadata": {
        "id": "2863a428"
      },
      "source": [
        "# Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fa39b8f",
      "metadata": {
        "id": "1fa39b8f"
      },
      "outputs": [],
      "source": [
        "# list of categorical variables to plot\n",
        "cat_vars = ['Education', 'Marital_Status', 'Dt_Customer', \n",
        "            'Kidhome', 'Teenhome', 'Complain']\n",
        "\n",
        "# create figure with subplots\n",
        "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(15, 10))\n",
        "axs = axs.flatten()\n",
        "\n",
        "# create barplot for each categorical variable\n",
        "for i, var in enumerate(cat_vars):\n",
        "    sns.countplot(x=var, hue='Response', data=df, ax=axs[i])\n",
        "    axs[i].set_xticklabels(axs[i].get_xticklabels(), rotation=90)\n",
        "\n",
        "# adjust spacing between subplots\n",
        "fig.tight_layout()\n",
        "\n",
        "# show plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f6710e3",
      "metadata": {
        "id": "9f6710e3"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "# get list of categorical variables\n",
        "cat_vars = ['Education', 'Marital_Status', 'Dt_Customer']\n",
        "\n",
        "# create figure with subplots\n",
        "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(15, 10))\n",
        "axs = axs.flatten()\n",
        "\n",
        "# create histplot for each categorical variable\n",
        "for i, var in enumerate(cat_vars):\n",
        "    sns.histplot(x=var, hue='Response', data=df, ax=axs[i], multiple=\"fill\", kde=False, element=\"bars\", fill=True, stat='density')\n",
        "    axs[i].set_xticklabels(df[var].unique(), rotation=90)\n",
        "    axs[i].set_xlabel(var)\n",
        "\n",
        "# adjust spacing between subplots\n",
        "fig.tight_layout()\n",
        "\n",
        "# show plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efaf8877",
      "metadata": {
        "id": "efaf8877"
      },
      "outputs": [],
      "source": [
        "cat_vars = ['Education', 'Marital_Status', 'Dt_Customer', \n",
        "            'Kidhome', 'Teenhome', 'Complain']\n",
        "\n",
        "# create a figure and axes\n",
        "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(15, 15))\n",
        "\n",
        "# create a pie chart for each categorical variable\n",
        "for i, var in enumerate(cat_vars):\n",
        "    if i < len(axs.flat):\n",
        "        # count the number of occurrences for each category\n",
        "        cat_counts = df[var].value_counts()\n",
        "\n",
        "        # create a pie chart\n",
        "        axs.flat[i].pie(cat_counts, labels=cat_counts.index, autopct='%1.1f%%', startangle=90)\n",
        "\n",
        "        # set a title for each subplot\n",
        "        axs.flat[i].set_title(f'{var} Distribution')\n",
        "\n",
        "# adjust spacing between subplots\n",
        "fig.tight_layout()\n",
        "\n",
        "# show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51fda92a",
      "metadata": {
        "id": "51fda92a"
      },
      "outputs": [],
      "source": [
        "num_vars = ['Year_Birth', 'Income', 'Recency', 'MntWines', 'MntFruits',\n",
        "           'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts',\n",
        "           'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases',\n",
        "           'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth']\n",
        "\n",
        "fig, axs = plt.subplots(nrows=3, ncols=5, figsize=(20, 10))\n",
        "axs = axs.flatten()\n",
        "\n",
        "for i, var in enumerate(num_vars):\n",
        "    sns.boxplot(x=var, data=df, ax=axs[i])\n",
        "\n",
        "fig.tight_layout()\n",
        "\n",
        "# remove the 15th subplot\n",
        "fig.delaxes(axs[14])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7452b979",
      "metadata": {
        "id": "7452b979"
      },
      "outputs": [],
      "source": [
        "num_vars = ['Year_Birth', 'Income', 'Recency', 'MntWines', 'MntFruits',\n",
        "           'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts',\n",
        "           'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases',\n",
        "           'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth']\n",
        "\n",
        "fig, axs = plt.subplots(nrows=3, ncols=5, figsize=(20, 20))\n",
        "axs = axs.flatten()\n",
        "\n",
        "for i, var in enumerate(num_vars):\n",
        "    sns.boxplot(y=var, x='Response', data=df, ax=axs[i])\n",
        "\n",
        "fig.tight_layout()\n",
        "\n",
        "# remove the 15th subplot\n",
        "fig.delaxes(axs[14])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed191509",
      "metadata": {
        "id": "ed191509"
      },
      "outputs": [],
      "source": [
        "num_vars = ['Year_Birth', 'Income', 'Recency', 'MntWines', 'MntFruits',\n",
        "           'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts',\n",
        "           'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases',\n",
        "           'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth']\n",
        "\n",
        "fig, axs = plt.subplots(nrows=3, ncols=5, figsize=(20, 10))\n",
        "axs = axs.flatten()\n",
        "\n",
        "for i, var in enumerate(num_vars):\n",
        "    sns.violinplot(x=var, data=df, ax=axs[i])\n",
        "\n",
        "fig.tight_layout()\n",
        "\n",
        "# remove the 15th subplot\n",
        "fig.delaxes(axs[14])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8f9fced",
      "metadata": {
        "id": "b8f9fced"
      },
      "outputs": [],
      "source": [
        "num_vars = ['Year_Birth', 'Income', 'Recency', 'MntWines', 'MntFruits',\n",
        "           'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts',\n",
        "           'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases',\n",
        "           'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth']\n",
        "\n",
        "fig, axs = plt.subplots(nrows=3, ncols=5, figsize=(20, 20))\n",
        "axs = axs.flatten()\n",
        "\n",
        "for i, var in enumerate(num_vars):\n",
        "    sns.violinplot(y=var, data=df, x='Response', ax=axs[i])\n",
        "\n",
        "fig.tight_layout()\n",
        "\n",
        "# remove the 15th subplot\n",
        "fig.delaxes(axs[14])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d83b50f",
      "metadata": {
        "id": "4d83b50f"
      },
      "source": [
        "# Data Preprocessing Part 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "daebb4eb",
      "metadata": {
        "id": "daebb4eb"
      },
      "outputs": [],
      "source": [
        "#Check missing value\n",
        "check_missing = df.isnull().sum() * 100 / df.shape[0]\n",
        "check_missing[check_missing > 0].sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f828daf",
      "metadata": {
        "id": "4f828daf"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0011e6b",
      "metadata": {
        "id": "c0011e6b"
      },
      "outputs": [],
      "source": [
        "# Drop null value because its only 1%\n",
        "df.dropna(inplace=True)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9466dd31",
      "metadata": {
        "id": "9466dd31"
      },
      "outputs": [],
      "source": [
        "# Drop Complain column because its very  unbalanced\n",
        "df.drop(columns='Complain', inplace=True)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddc0cf99",
      "metadata": {
        "id": "ddc0cf99"
      },
      "source": [
        "# Label Encoding for each Object datatype "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adefc60f",
      "metadata": {
        "id": "adefc60f"
      },
      "outputs": [],
      "source": [
        "# Loop over each column in the DataFrame where dtype is 'object'\n",
        "for col in df.select_dtypes(include=['object']).columns:\n",
        "    \n",
        "    # Print the column name and the unique values\n",
        "    print(f\"{col}: {df[col].unique()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3838f219",
      "metadata": {
        "id": "3838f219"
      },
      "outputs": [],
      "source": [
        "# Replace 'YOLO' and 'Alone' with 'Single' in the 'Status' column\n",
        "df['Marital_Status'] = df['Marital_Status'].replace(['YOLO', 'Alone'], 'Single')\n",
        "df['Marital_Status'] = df['Marital_Status'].replace(['Together'], 'Married')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e30d2a5f",
      "metadata": {
        "id": "e30d2a5f"
      },
      "outputs": [],
      "source": [
        "# Remove Dt_Customer because its irrelevant for prediction\n",
        "df.drop(columns='Dt_Customer', inplace=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cb1d5a9",
      "metadata": {
        "id": "9cb1d5a9"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "# Loop over each column in the DataFrame where dtype is 'object'\n",
        "for col in df.select_dtypes(include=['object']).columns:\n",
        "    \n",
        "    # Initialize a LabelEncoder object\n",
        "    label_encoder = preprocessing.LabelEncoder()\n",
        "    \n",
        "    # Fit the encoder to the unique values in the column\n",
        "    label_encoder.fit(df[col].unique())\n",
        "    \n",
        "    # Transform the column using the encoder\n",
        "    df[col] = label_encoder.transform(df[col])\n",
        "    \n",
        "    # Print the column name and the unique encoded values\n",
        "    print(f\"{col}: {df[col].unique()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86cdbb83",
      "metadata": {
        "id": "86cdbb83"
      },
      "source": [
        "# Correlation Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2589c5b5",
      "metadata": {
        "id": "2589c5b5"
      },
      "outputs": [],
      "source": [
        "#Correlation Heatmap (print the correlation score each variables)\n",
        "plt.figure(figsize=(20, 16))\n",
        "sns.heatmap(df.corr(), fmt='.2g', annot=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ee4a9f7",
      "metadata": {
        "id": "4ee4a9f7"
      },
      "source": [
        "# Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7063470c",
      "metadata": {
        "id": "7063470c"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Select the features (X) and the target variable (y)\n",
        "X = df.drop('Response', axis=1)\n",
        "y = df['Response']\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "953dff57",
      "metadata": {
        "id": "953dff57"
      },
      "source": [
        "# Remove the Outlier from train data using Z-Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bfe30b2",
      "metadata": {
        "id": "6bfe30b2"
      },
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "\n",
        "# Define the columns for which you want to remove outliers\n",
        "selected_columns = ['Year_Birth', 'Income', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts',\n",
        "           'MntGoldProds', 'NumDealsPurchases','NumCatalogPurchases']\n",
        "\n",
        "# Calculate the Z-scores for the selected columns in the training data\n",
        "z_scores = np.abs(stats.zscore(X_train[selected_columns]))\n",
        "\n",
        "# Set a threshold value for outlier detection (e.g., 3)\n",
        "threshold = 3\n",
        "\n",
        "# Find the indices of outliers based on the threshold\n",
        "outlier_indices = np.where(z_scores > threshold)[0]\n",
        "\n",
        "# Remove the outliers from the training data\n",
        "X_train = X_train.drop(X_train.index[outlier_indices])\n",
        "y_train = y_train.drop(y_train.index[outlier_indices])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dba06805",
      "metadata": {
        "id": "dba06805"
      },
      "source": [
        "# Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8029145",
      "metadata": {
        "id": "f8029145"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "dtree = DecisionTreeClassifier(class_weight='balanced')\n",
        "param_grid = {\n",
        "    'max_depth': [3, 4, 5, 6, 7, 8],\n",
        "    'min_samples_split': [2, 3, 4],\n",
        "    'min_samples_leaf': [1, 2, 3, 4],\n",
        "    'random_state': [0, 42]\n",
        "}\n",
        "\n",
        "# Perform a grid search with cross-validation to find the best hyperparameters\n",
        "grid_search = GridSearchCV(dtree, param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cd5b044",
      "metadata": {
        "id": "7cd5b044"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dtree = DecisionTreeClassifier(random_state=0, max_depth=8, min_samples_leaf=1, min_samples_split=3, class_weight='balanced')\n",
        "dtree.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee7632af",
      "metadata": {
        "id": "ee7632af"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = dtree.predict(X_test)\n",
        "print(\"Accuracy Score :\", round(accuracy_score(y_test, y_pred)*100 ,2), \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "718c07a6",
      "metadata": {
        "id": "718c07a6"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, jaccard_score, log_loss\n",
        "print('F-1 Score : ',(f1_score(y_test, y_pred, average='micro')))\n",
        "print('Precision Score : ',(precision_score(y_test, y_pred, average='micro')))\n",
        "print('Recall Score : ',(recall_score(y_test, y_pred, average='micro')))\n",
        "print('Jaccard Score : ',(jaccard_score(y_test, y_pred, average='micro')))\n",
        "print('Log Loss : ',(log_loss(y_test, y_pred)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b9f2caa",
      "metadata": {
        "id": "0b9f2caa"
      },
      "outputs": [],
      "source": [
        "imp_df = pd.DataFrame({\n",
        "    \"Feature Name\": X_train.columns,\n",
        "    \"Importance\": dtree.feature_importances_\n",
        "})\n",
        "fi = imp_df.sort_values(by=\"Importance\", ascending=False)\n",
        "\n",
        "fi2 = fi.head(10)\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.barplot(data=fi2, x='Importance', y='Feature Name')\n",
        "plt.title('Top 10 Feature Importance Each Attributes (Decision Tree)', fontsize=18)\n",
        "plt.xlabel ('Importance', fontsize=16)\n",
        "plt.ylabel ('Feature Name', fontsize=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6ea7081",
      "metadata": {
        "id": "d6ea7081"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "explainer = shap.TreeExplainer(dtree)\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "shap.summary_plot(shap_values, X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "275b09f8",
      "metadata": {
        "id": "275b09f8"
      },
      "outputs": [],
      "source": [
        "# compute SHAP values\n",
        "explainer = shap.TreeExplainer(dtree)\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "shap.summary_plot(shap_values[1], X_test.values, feature_names = X_test.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbc41810",
      "metadata": {
        "id": "dbc41810"
      },
      "outputs": [],
      "source": [
        "# compute SHAP values\n",
        "explainer = shap.TreeExplainer(dtree)\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "shap.summary_plot(shap_values[1], X_test.values, feature_names = X_test.columns, plot_type=\"violin\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f1b1135",
      "metadata": {
        "id": "1f1b1135"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(5,5))\n",
        "sns.heatmap(data=cm,linewidths=.5, annot=True,  cmap = 'Blues')\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')\n",
        "all_sample_title = 'Accuracy Score for Decision Tree: {0}'.format(dtree.score(X_test, y_test))\n",
        "plt.title(all_sample_title, size = 15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fc7f1c9",
      "metadata": {
        "id": "2fc7f1c9"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "y_pred_proba = dtree.predict_proba(X_test)[:][:,1]\n",
        "\n",
        "df_actual_predicted = pd.concat([pd.DataFrame(np.array(y_test), columns=['y_actual']), pd.DataFrame(y_pred_proba, columns=['y_pred_proba'])], axis=1)\n",
        "df_actual_predicted.index = y_test.index\n",
        "\n",
        "fpr, tpr, tr = roc_curve(df_actual_predicted['y_actual'], df_actual_predicted['y_pred_proba'])\n",
        "auc = roc_auc_score(df_actual_predicted['y_actual'], df_actual_predicted['y_pred_proba'])\n",
        "\n",
        "plt.plot(fpr, tpr, label='AUC = %0.4f' %auc)\n",
        "plt.plot(fpr, fpr, linestyle = '--', color='k')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve', size = 15)\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8d37aac",
      "metadata": {
        "id": "e8d37aac"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e424eacf",
      "metadata": {
        "id": "e424eacf"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "rfc = RandomForestClassifier(class_weight='balanced')\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [None, 5, 10],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'random_state': [0, 42]\n",
        "}\n",
        "\n",
        "# Perform a grid search with cross-validation to find the best hyperparameters\n",
        "grid_search = GridSearchCV(rfc, param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f75a09a",
      "metadata": {
        "id": "8f75a09a"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc = RandomForestClassifier(random_state=42, max_features='sqrt', n_estimators=200, class_weight='balanced')\n",
        "rfc.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "728ff544",
      "metadata": {
        "id": "728ff544"
      },
      "outputs": [],
      "source": [
        "y_pred = rfc.predict(X_test)\n",
        "print(\"Accuracy Score :\", round(accuracy_score(y_test, y_pred)*100 ,2), \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc51a1c1",
      "metadata": {
        "id": "bc51a1c1"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, jaccard_score, log_loss\n",
        "print('F-1 Score : ',(f1_score(y_test, y_pred, average='micro')))\n",
        "print('Precision Score : ',(precision_score(y_test, y_pred, average='micro')))\n",
        "print('Recall Score : ',(recall_score(y_test, y_pred, average='micro')))\n",
        "print('Jaccard Score : ',(jaccard_score(y_test, y_pred, average='micro')))\n",
        "print('Log Loss : ',(log_loss(y_test, y_pred)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fd66ec4",
      "metadata": {
        "id": "4fd66ec4"
      },
      "outputs": [],
      "source": [
        "imp_df = pd.DataFrame({\n",
        "    \"Feature Name\": X_train.columns,\n",
        "    \"Importance\": rfc.feature_importances_\n",
        "})\n",
        "fi = imp_df.sort_values(by=\"Importance\", ascending=False)\n",
        "\n",
        "fi2 = fi.head(10)\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.barplot(data=fi2, x='Importance', y='Feature Name')\n",
        "plt.title('Top 10 Feature Importance Each Attributes (Random Forest)', fontsize=18)\n",
        "plt.xlabel ('Importance', fontsize=16)\n",
        "plt.ylabel ('Feature Name', fontsize=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15ff01dd",
      "metadata": {
        "id": "15ff01dd"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "explainer = shap.TreeExplainer(rfc)\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "shap.summary_plot(shap_values, X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "451ba32c",
      "metadata": {
        "id": "451ba32c"
      },
      "outputs": [],
      "source": [
        "# compute SHAP values\n",
        "explainer = shap.TreeExplainer(rfc)\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "shap.summary_plot(shap_values[1], X_test.values, feature_names = X_test.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46636a87",
      "metadata": {
        "id": "46636a87"
      },
      "outputs": [],
      "source": [
        "# compute SHAP values\n",
        "explainer = shap.TreeExplainer(rfc)\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "shap.summary_plot(shap_values[1], X_test.values, feature_names = X_test.columns, plot_type=\"violin\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e392794",
      "metadata": {
        "id": "2e392794"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(5,5))\n",
        "sns.heatmap(data=cm,linewidths=.5, annot=True,  cmap = 'Blues')\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')\n",
        "all_sample_title = 'Accuracy Score for Random Forest: {0}'.format(rfc.score(X_test, y_test))\n",
        "plt.title(all_sample_title, size = 15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee0bf52a",
      "metadata": {
        "id": "ee0bf52a"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "y_pred_proba = rfc.predict_proba(X_test)[:][:,1]\n",
        "\n",
        "df_actual_predicted = pd.concat([pd.DataFrame(np.array(y_test), columns=['y_actual']), pd.DataFrame(y_pred_proba, columns=['y_pred_proba'])], axis=1)\n",
        "df_actual_predicted.index = y_test.index\n",
        "\n",
        "fpr, tpr, tr = roc_curve(df_actual_predicted['y_actual'], df_actual_predicted['y_pred_proba'])\n",
        "auc = roc_auc_score(df_actual_predicted['y_actual'], df_actual_predicted['y_pred_proba'])\n",
        "\n",
        "plt.plot(fpr, tpr, label='AUC = %0.4f' %auc)\n",
        "plt.plot(fpr, fpr, linestyle = '--', color='k')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve', size = 15)\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07fb2b83",
      "metadata": {
        "id": "07fb2b83"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}